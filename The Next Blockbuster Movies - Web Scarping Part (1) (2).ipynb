{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4873dab6",
   "metadata": {},
   "source": [
    "# The Next Blockbuster Movies - Web Scarping Part "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446dd3ce",
   "metadata": {},
   "source": [
    "In this project we will predict the next successful movies. We will learn about different parameters of successful past films, (such as genre, budget, language,total income and more)\n",
    "\n",
    "In this section we will deal with Crawling \\ Web Scraping.\n",
    "\n",
    "Our data aquisition is devided to 2 parts - 2 websites - Past & Future. Our dataset will be collected from 2 diffrents data websites.\n",
    "\n",
    "We gathered information from 2 different website , we used **Box Office Mojo** for exploring the past movies - Containing important information about the revenue of the most successful movies.\n",
    "\n",
    "For the second part of our web scraping, we will explore the future movies world from **IMDB** - this is a famous and well known website, which contains a lot of information about all times movies, and in our case, we chose to focus the future movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583f6ff",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd6015",
   "metadata": {},
   "source": [
    "the next block will be responsible for installing and importing the necessary libraries and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c5fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "import time\n",
    "import os # for testing use only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ffa16",
   "metadata": {},
   "source": [
    "# past movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96b989",
   "metadata": {},
   "source": [
    "We will scrap the data from the website called **Box Office Mojo** ,  \n",
    "This will help us understand what characteristics are common to most successful past films.  \n",
    "Due to our goal - predicting the WORLDWIDE INCOME of a movie, we will try to collect financial features as we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba5b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_val = None \n",
    "rank = []\n",
    "title = []\n",
    "linkP = [] \n",
    "year = []   \n",
    "#Begining of the colums starts now \n",
    "Rank = [] # 1 V \n",
    "MPAA_Rating = []  \n",
    "Link = [] #3  V  \n",
    "Generes = [] #4 pp\n",
    "Name = [] #5  V pp\n",
    "RunningTime = []  #6 pp\n",
    "DomesticDistributor = [] #7 ??? future \n",
    "Budget = [] #8 pp\n",
    "WorldwideIncome = [] #9 V only for past && ML  \n",
    "InternationalIncome = [] # 10  V only for past && ML \n",
    "DomesticIncome = [] #11 V only for past && ML  \n",
    "DomesicIncomePercent = []  #12   or with clcuate only for past \n",
    "InternationalIncomePercent = []   # 13 or with clcuate  only for past \n",
    "TextShortCut = [] # 14 pp \n",
    "DomisticOpeningVal = [] # 15 V only for past\n",
    "Date = [] # 16  pp \n",
    "Language = [] # 17 pp only for the future \n",
    "Director = [] # 18  pp only for the future \n",
    "Location = [] # 19   pp only for the future\n",
    "MovieTrack = [] # 20  pp only for the future \n",
    "Writers = [] # 21 pp only for the future \n",
    "Year = [] # 22  V for past, pp for future \n",
    "Stars = [] # 23 or \n",
    "KeyWords = [] # 24 only for the future  \n",
    "TagLine = [] # 25  only for the future \n",
    "CountryOrigin = [] # 26 only for the future \n",
    "ProdCompany = [] # 27 only for the future \n",
    "AmountMarjets = [] # 28 \n",
    "AnotherMovieNAME = [] # 28\n",
    "MovieStatus  = [] # 29 or \n",
    "SecondStar=[] #30\n",
    "#End of our colums  \n",
    "\n",
    "#this is the begining of past data frame colums \n",
    "initial_rank = 1000 \n",
    "rankN = []\n",
    "titleN = []\n",
    "linkN = [] \n",
    "yearN =  []  \n",
    "MovieStatN = []  \n",
    "MPAAN = [] \n",
    "GenerN = [] \n",
    "RunTimeN = [] \n",
    "empty_val = None  \n",
    "ShortCutN = [] \n",
    "\n",
    "miniWords = [] \n",
    "miniWordss = [] \n",
    "miniWordsss = [] \n",
    "miniw = [] \n",
    "\n",
    "BudgetN = []\n",
    "TextShortCutN = [] # 14 pp \n",
    "DateN = [] # 16  pp \n",
    "LanguageN = [] # 17 pp only for the future \n",
    "DirectorN = [] # 18  pp only for the future \n",
    "LocationN = [] # 19   pp only for the future\n",
    "MovieTrackN = [] # 20  pp only for the future \n",
    "WritersN = [] # 21 pp only for the future \n",
    "YearN = [] # 22  V for past, pp for future \n",
    "MainStarN = [] # 23 or \n",
    "SecondStarN=[]\n",
    "KeyWordsN = [] # 24 only for the future  \n",
    "TagLineN = [] # 25  only for the future \n",
    "CountryOriginN = [] # 26 only for the future \n",
    "ProdCompanyN = [] # 27 only for the future \n",
    "AnotherMovieNAMEN = [] # 28 \n",
    "SoundmixN = [] # 30  \n",
    "AspectRatioN = [] # 31  \n",
    "#this is the end of past data frame colums \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "urlPastMovies = [\"https://www.boxofficemojo.com/chart/top_lifetime_gross/?area=XWW\", \n",
    "         \"https://www.boxofficemojo.com/chart/top_lifetime_gross/?area=XWW&offset=200\", \n",
    "         \"https://www.boxofficemojo.com/chart/top_lifetime_gross/?area=XWW&offset=400\", \n",
    "         \"https://www.boxofficemojo.com/chart/top_lifetime_gross/?area=XWW&offset=600\", \n",
    "         \"https://www.boxofficemojo.com/chart/top_lifetime_gross/?area=XWW&offset=800\" ]\n",
    "    \n",
    "\n",
    "# In each 200 grossing movies page \n",
    "NumEachPage = 200 \n",
    "# each page of our bluckbuster we have 200 movies in a table \n",
    "NumofPage = 5 \n",
    "# we explore 1000 past bluckbuster movies, devided to 5 pages \n",
    "\n",
    "#begining of past movies crawling as described above \n",
    "\n",
    "for url in urlPastMovies : \n",
    "    # each url include 200 movies between 1-1000  \n",
    "    #souping\n",
    "    time.sleep(2) \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    soup.prettify() \n",
    "    #souping\n",
    "    MovieRanks = soup.find_all('td', {'class': 'a-text-right mojo-header-column mojo-truncate mojo-field-type-rank'}) \n",
    "    MovieTitle = soup.find_all('td', {'class': 'a-text-left mojo-field-type-title'})\n",
    "    # print(len(MovieTitle)) \n",
    "    MovieYear = soup.find_all('td', {'class': 'a-text-left mojo-field-type-year'}) \n",
    "    MovieLink = soup.find_all('td', {'class': 'a-text-left mojo-field-type-year'}) \n",
    "    # MovieLink = soup.find_all('a', {'class': 'a-text-left mojo-field-type-year'}) \n",
    "\n",
    "    \n",
    "    for mo in MovieTitle: \n",
    "        a_tag = mo.find('a') \n",
    "        UrlAdd = a_tag['href']  \n",
    "        linkk = 'https://www.boxofficemojo.com' + UrlAdd \n",
    "        # print(linkk) #check \n",
    "        linkP.append(linkk)\n",
    "    \n",
    "    for j in range(NumEachPage) : \n",
    "        MovieRanks[j]= MovieRanks[j].text\n",
    "        MovieTitle[j] = MovieTitle[j].text \n",
    "        MovieYear[j] = MovieYear[j].text  \n",
    "         \n",
    "    #arranging the final lists  \n",
    "    rank = rank + MovieRanks \n",
    "    title = title + MovieTitle \n",
    "    year = year + MovieYear\n",
    "    linkP = linkP \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36428b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue of past movies crawling as described above \n",
    "\n",
    "x = 0 \n",
    "LenSpan = 0  \n",
    "stausList =[]\n",
    "geners_val = 0\n",
    "\n",
    "\n",
    "\n",
    "for PastLink in linkP:   \n",
    "    #souping\n",
    "    time.sleep(1) \n",
    "    url=PastLink \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    soup.prettify()\n",
    "    #end souping \n",
    "    spanRes = []  \n",
    "    Description=soup.find('span',{'class':'a-size-medium'}).get_text()\n",
    "    TextShortCut.append(Description)  \n",
    "    table1 = soup.find('div', \n",
    "                   {'class': 'a-section a-spacing-none mojo-summary-values mojo-hidden-from-mobile'}) \n",
    "    table2 = table1.find_all('div', {'class': 'a-section a-spacing-none'})\n",
    "    \n",
    "    for t in table2: \n",
    "        sp = t.find_all('span')  # getting spans each class \n",
    "        for spo in sp:  # exploring each span onto the spans re\n",
    "            spanRes.append(spo.text) \n",
    "    print(len(spanRes))    \n",
    "    idx = 0   \n",
    "    stausList = [0,0,0,0,0,0,0]\n",
    "    \n",
    "    LenSpan = len(spanRes)\n",
    "    \n",
    "    for i in range(LenSpan): \n",
    "        if(spanRes[i]==\"Domestic Distributor\"): \n",
    "            domistic_clean=spanRes[i+1].replace('See full company information', '')\n",
    "            domistic_clean=domistic_clean.replace('\\n\\n', '')\n",
    "            DomesticDistributor.append(domistic_clean)\n",
    "            stausList[0] = 1 \n",
    "        if(spanRes[i]==\"Domestic Opening\"): \n",
    "            DomisticOpeningVal.append(spanRes[i+1])\n",
    "            stausList[1] = 1 \n",
    "        if(spanRes[i]==\"Budget\"): \n",
    "            Budget.append(spanRes[i+1])\n",
    "            stausList[2] = 1 \n",
    "        if(spanRes[i]==\"Earliest Release Date\"): \n",
    "#             Date.append(spanRes[i+1])\n",
    "            date_clean=spanRes[i+1]\n",
    "            date_clean = date_clean[:date_clean.rfind(\"(\")]\n",
    "            date_clean=date_clean.replace('\\n            ', '') \n",
    "            Date.append(date_clean)\n",
    "            stausList[3] = 1 \n",
    "        if(spanRes[i]==\"MPAA\"): \n",
    "            MPAA_Rating.append(spanRes[i+1])\n",
    "            stausList[4] = 1\n",
    "        if(spanRes[i]==\"Running Time\"): \n",
    "            RunningTime.append(spanRes[i+1])\n",
    "            stausList[5] = 1\n",
    "        if(spanRes[i]==\"Genres\"):\n",
    "            geners_clean= spanRes[i+1].replace('\\n', '')\n",
    "            geners_clean=geners_clean.replace('           ',',')\n",
    "            Generes.append(geners_clean)\n",
    "            stausList[6] = 1\n",
    "        \n",
    "        \n",
    "  \n",
    "    if(stausList[0] == 0):\n",
    "        DomesticDistributor.append(empty_val)\n",
    "    if(stausList[1] == 0):\n",
    "        DomisticOpeningVal.append(empty_val)\n",
    "    if(stausList[2] == 0):\n",
    "        Budget.append(empty_val)\n",
    "    if(stausList[3] == 0):\n",
    "        Date.append(empty_val) \n",
    "    if(stausList[4] == 0):\n",
    "        MPAA_Rating.append(empty_val) \n",
    "    if(stausList[5] == 0):\n",
    "        RunningTime.append(empty_val) \n",
    "    if(stausList[6] == 0):\n",
    "        Generes.append(empty_val) \n",
    "            \n",
    "\n",
    " \n",
    "                                        #finance table\n",
    "    tableFin = soup.find_all('div',\n",
    "                     {'class': 'a-section a-spacing-none mojo-gutter mojo-summary-table'},\n",
    "                     {'class': 'a-section a-spacing-none mojo-performance-summary'},\n",
    "                     {'class': 'a-section a-spacing-none mojo-performance-summary'},\n",
    "                     {'class': 'a-section a-spacing-none mojo-performance-summary-table'})\n",
    "    tableFin =  soup.find('div',{'class': 'a-section a-spacing-none'})  \n",
    "    spansFin = soup.find_all('span',   {'class': 'money'})\n",
    " \n",
    "    DomesticIncome.append(spansFin[0].text)\n",
    "    InternationalIncome.append(spansFin[1].text)\n",
    "    WorldwideIncome.append(spansFin[2].text)\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some editing of finance data \n",
    "\n",
    "for d in range(0,1000): \n",
    "    \n",
    "    W = WorldwideIncome[d]\n",
    "    W = W.replace(',', '') \n",
    "    W = W.replace('$','')   \n",
    "    W = int(W)\n",
    "     \n",
    "    D = DomesticIncome[d]\n",
    "    D = D.replace(',', '')\n",
    "    D = D.replace('$','')  \n",
    "    D = int(D)\n",
    "    \n",
    "    I = InternationalIncome[d]\n",
    "    I = I.replace(',', '') \n",
    "    I = I.replace('$','') \n",
    "    I = int(I) \n",
    "    \n",
    "    Ip = I / W  \n",
    "    Dp = D / W  \n",
    "    \n",
    "    DomesicIncomePercent.append(Dp) \n",
    "    InternationalIncomePercent.append(Ip) \n",
    "    \n",
    "    InternationalIncome[d]  = I  \n",
    "    WorldwideIncome[d] = W\n",
    "    DomesticIncome[d] = D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some editing of finance data \n",
    "\n",
    "for d in range(0,1000):  \n",
    "    if( (  isinstance( DomisticOpeningVal[d], int ) != 1 ) & (DomisticOpeningVal[d]!= None)) : \n",
    "        OP = DomisticOpeningVal[d]\n",
    "        OP = OP.replace(',', '') \n",
    "        OP = OP.replace('$','')   \n",
    "        OP = int(OP)\n",
    "        DomisticOpeningVal[d] = OP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e5723",
   "metadata": {},
   "source": [
    "# Future Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5dbef6",
   "metadata": {},
   "source": [
    "we will try to collect lot of data from **IMDB**  ,  \n",
    "Then we will try to predict the revenue of future films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put empty for past \n",
    "LanguageP = [] # 17 pp only for the future \n",
    "DirectorP = [] # 18  pp only for the future \n",
    "LocationP = [] # 19   pp only for the future\n",
    "MovieTrackP = [] # 20  pp only for the future \n",
    "StarsP = [] # 23   only for the future \n",
    "KeyWordsP = [] # 24 only for the future  \n",
    "TagLineP = [] # 25  only for the future \n",
    "CountryOriginP = [] # 26 only for the future \n",
    "ProdCompanyP = [] # 27 only for the future \n",
    "AnotherMovieNAMEP = [] # 28\n",
    "SoundMixP = [] # 30\n",
    "AspectRatioP = [] # 31 \n",
    "MovieStatusP = [] \n",
    "statP = \"Brodcasted\"\n",
    "star2P = []  \n",
    "    \n",
    "WorldwideIncomeF= []\n",
    "InternationalIncomeF= []\n",
    "DomesticIncomeF= []\n",
    "DomesicIncomePercentF= []\n",
    "InternationalIncomePercentF= []\n",
    "DomisticOpeningValF= []\n",
    "DomesticDistributorF= []\n",
    "empty_val = None \n",
    " \n",
    "for e in range(0,1000): \n",
    "    LanguageP.append(empty_val)\n",
    "    DirectorP.append(empty_val) \n",
    "    LocationP.append(empty_val)\n",
    "    MovieTrackP.append(empty_val)\n",
    "    StarsP.append(empty_val)\n",
    "    KeyWordsP.append(empty_val)  \n",
    "    TagLineP.append(empty_val)\n",
    "    CountryOriginP.append(empty_val)\n",
    "    ProdCompanyP.append(empty_val) \n",
    "    AnotherMovieNAMEP.append(empty_val)\n",
    "    SoundMixP.append(empty_val)\n",
    "    AspectRatioP.append(empty_val)\n",
    "    MovieStatusP.append(statP)\n",
    "    star2P.append(empty_val)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#future movies crawling as described above \n",
    "\n",
    "UrlFutureMovies = [\"https://www.imdb.com/list/ls056612799/?ref_=otl_3\", \n",
    "                  \"https://www.imdb.com/list/ls056612799/?ref_=otl_3&sort=list_order,asc&st_dt=&mode=detail&page=2\", \n",
    "                  \"https://www.imdb.com/list/ls056612799/?ref_=otl_3&sort=list_order,asc&st_dt=&mode=detail&page=3\", \n",
    "                  \"https://www.imdb.com/list/ls056612799/?ref_=otl_3&sort=list_order,asc&st_dt=&mode=detail&page=4\", \n",
    "                   \"https://www.imdb.com/list/ls056612799/?ref_=otl_3&sort=list_order,asc&st_dt=&mode=detail&page=5\", \n",
    "                   \"https://www.imdb.com/list/ls056612799/?ref_=otl_3&sort=list_order,asc&st_dt=&mode=detail&page=6\", \n",
    "                   \"https://www.imdb.com/list/ls056612799/?ref_=otl_3&sort=list_order,asc&st_dt=&mode=detail&page=7\",\n",
    "                   \"https://www.imdb.com/list/ls056612799/?ref_=otl_3&sort=list_order,asc&st_dt=&mode=detail&page=8\"  ]\n",
    "initial_rank = 1000 \n",
    "#future list to datatframe\n",
    "rankN = []\n",
    "titleN = []\n",
    "linkN = [] \n",
    "yearN =  []  \n",
    "MovieStatN = []  \n",
    "MPAAN = [] \n",
    "GenerN = [] \n",
    "RunTimeN = [] \n",
    "empty_val = None  \n",
    "ShortCutN = [] \n",
    "\n",
    "miniWords = [] \n",
    "miniWordss = [] \n",
    "miniWordsss = [] \n",
    "miniw = [] \n",
    "\n",
    "BudgetN = []\n",
    "TextShortCutN = [] # 14 pp \n",
    "DateN = [] # 16  pp \n",
    "LanguageN = [] # 17 pp only for the future \n",
    "DirectorN = [] # 18  pp only for the future \n",
    "LocationN = [] # 19   pp only for the future\n",
    "MovieTrackN = [] # 20  pp only for the future \n",
    "WritersN = [] # 21 pp only for the future \n",
    "YearN = [] # 22  V for past, pp for future \n",
    "MainStarN = [] # 23 or \n",
    "SecondStarN=[]\n",
    "KeyWordsN = [] # 24 only for the future  \n",
    "TagLineN = [] # 25  only for the future \n",
    "CountryOriginN = [] # 26 only for the future \n",
    "ProdCompanyN = [] # 27 only for the future \n",
    "AnotherMovieNAMEN = [] # 28 \n",
    "SoundmixN = [] # 30  \n",
    "AspectRatioN = [] # 31  \n",
    "FM_Amount = 0 \n",
    "#future list to datatframe\n",
    "\n",
    "#future movies crawling as described above - in this loop we will import the basic data of future movies\n",
    "# including specified link per movie from 2022 - 2028 \n",
    "#after these, we will pass each link to scrap it more \n",
    "\n",
    "for url in UrlFutureMovies: \n",
    "    #souping\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    soup.prettify() \n",
    "    #souping\n",
    "    bulets = soup.find_all('div', {'class': 'lister-item-content'})   \n",
    "    Nlen = len(bulets)\n",
    "    for b in bulets:   \n",
    "        #here add try except !!! \n",
    "        FM_Amount = FM_Amount + 1 \n",
    "        initial_rank = initial_rank + 1\n",
    "        rankN.append(initial_rank) \n",
    "        print('t')\n",
    "        #Basic details - NAME, LINK \n",
    "        #link of movies\n",
    "        basicD = b.find('h3',  {'class': 'lister-item-header'} )\n",
    "        mname = basicD.find('a') \n",
    "        mlink = mname['href']\n",
    "        mlink = \"https://www.imdb.com\" + mlink + \"?ref_=ttls_li_tt\"\n",
    "        linkN.append(mlink)\n",
    "        #name of movie\n",
    "        name = basicD.text \n",
    "        name= name.replace('\\n\\n', '')\n",
    "        name= name.replace('\\n', '')\n",
    "        name1 = name[name.rfind(\".\"):]\n",
    "        name2 = name1[:name1.rfind(\"(\")]\n",
    "        name3=name2.replace('.', '')\n",
    "        titleN.append(name3)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #movie status \n",
    "        try: \n",
    "            st = b.find('p', {'class' : 'text-muted text-small'}) \n",
    "            MovieStatus = st.find('b')  \n",
    "            MovieStatus = MovieStatus.text \n",
    "            MovieStatN.append(MovieStatus)\n",
    "        except: \n",
    "            MovieStatN.append(empty_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # movie MPAA\n",
    "        try:\n",
    "            MPAA_N = b.find('span', {'class' : 'certificate'})\n",
    "            MPAAN.append(MPAA_N.text)\n",
    "            \n",
    "        except: \n",
    "            MPAAN.append(empty_val)    \n",
    "            \n",
    " # movie running time \n",
    "        try:\n",
    "            runTime = b.find('span', {'class' : 'runtime'} )\n",
    "            runTime=runTime.text\n",
    "            runtime2=runTime.replace('min', '')\n",
    "            runtime3=runtime2.replace(' ','')\n",
    "            int_runtime=(int(runtime3))\n",
    "            hours=int(int_runtime/60)\n",
    "            hours_str=str(hours)\n",
    "            \n",
    "            minutes=int_runtime%60\n",
    "            minutes_str=str(minutes)\n",
    "            \n",
    "            str1=hours_str+\" hr \"+minutes_str+\" min\"\n",
    "            RunTimeN.append(str1)\n",
    "        except: \n",
    "            RunTimeN.append(empty_val)\n",
    "            \n",
    "        try:   \n",
    "            gen = b.find('span', {'class' : 'genre'} )\n",
    "            gen=gen.text\n",
    "            gen= gen.replace('\\n', '')\n",
    "            gen= gen.replace('  ',  '')\n",
    "            GenerN.append(gen)\n",
    "        except:  \n",
    "            GenerN.append(empty_val) \n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "#continue future movies crawling as described above  \n",
    "#after these, we will pass each link to scrap it more \n",
    "       \n",
    "for urlM in linkN:      \n",
    "    \n",
    "    response = requests.get(urlM)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    soup.prettify()\n",
    "    #end souping \n",
    "    \n",
    "    try:\n",
    "        Dis= soup.find('div', {'class': 'sc-388740f9-0 hJjREK'},\n",
    "                         {'class':'ipc-overflowText ipc-overflowText--pageSection ipc-overflowText--height-long ipc-overflowText--long ipc-overflowText--base'})\n",
    "        Dis=soup.find('div', {'class': 'ipc-html-content ipc-html-content--base'}).text\n",
    "        TextShortCutN.append(Dis)\n",
    "    except:  \n",
    "        TextShortCutN.append(empty_val)\n",
    "            \n",
    "        \n",
    "    try:\n",
    "#         release_date=soup.find('div',{'class':'sc-5766672e-2 bweBzH'}).text \n",
    "        release_date=soup.find('div',{'class':'sc-5766672e-2 bweBzH'})\n",
    "        release_date=release_date.text \n",
    "        release_date=release_date.replace('Releases', '')\n",
    "        release_date=release_date.replace('Expected', '')\n",
    "        DateN.append(release_date)\n",
    "    except:\n",
    "        DateN.append(empty_val) \n",
    "            \n",
    "            \n",
    "    try:\n",
    "        res = soup.find('ul',  { 'class' : 'ipc-metadata-list ipc-metadata-list--dividers-all sc-18baf029-10 jIsryf ipc-metadata-list--base'})\n",
    "        director=res.find('a',{'class':'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'})\n",
    "        DirectorN.append(director.text) \n",
    "    except: \n",
    "        DirectorN.append(empty_val) \n",
    "                                            #actors\n",
    "    try:\n",
    "        actor=soup.find('a',{'data-testid':'title-cast-item__actor'})\n",
    "        actor=actor.text \n",
    "        MainStarN.append(actor) \n",
    "    except:\n",
    "        MainStarN.append(empty_val) \n",
    "        \n",
    "    try:\n",
    "        actor2=soup.find_all('a',{'data-testid':'title-cast-item__actor'})[1]\n",
    "    \n",
    "        actor2=actor2.text\n",
    "        SecondStarN.append(actor)\n",
    "    \n",
    "    except:\n",
    "         SecondStarN.append(empty_val)\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        res = soup.find('div',  { 'class' : 'ipc-chip-list sc-55203d61-0 ciGQlL' } )\n",
    "        names = res.find_all('a', { 'class' : 'ipc-chip ipc-chip--on-base' } )  \n",
    "        miniWords.clear()\n",
    "        for n in names: \n",
    "            miniWords.append(n.text) \n",
    "        KeyWordsN.append(miniWords)\n",
    "    except:\n",
    "        KeyWordsN.append(empty_val)  \n",
    "        \n",
    "    try:\n",
    "        yearf =  soup.find('span', {'class': 'sc-8c396aa2-2 itZqyK' }) \n",
    "        yearf =  yearf.text  \n",
    "        yearN.append(yearf)\n",
    "    except:\n",
    "        yearN.append(empty_val)\n",
    "        \n",
    "    try:\n",
    "        tagline  =  soup.find('li', {'role': 'presentation'},\n",
    "                          {'class' : 'ipc-metadata-list__item ipc-metadata-list-item--link'}, \n",
    "                           {'data-testid' : 'storyline-taglines'}  ) \n",
    "        tag =  soup.find('span', { 'class' : 'ipc-metadata-list-item__list-content-item' })\n",
    "        tag = tag.text \n",
    "        TagLineN.append(tag) \n",
    "    except:\n",
    "        TagLineN.append(empty_val)\n",
    "            \n",
    "    try:\n",
    "        movtrack = soup.find('span', { 'class' : 'soundtrack-trackname' } )\n",
    "        movtrack=movtrack.text\n",
    "        MovieTrackN.append(movtrack)\n",
    "    except:\n",
    "        MovieTrackN.append(empty_val)\n",
    "         \n",
    "    try:\n",
    "        res = soup.find('li',  { 'data-testid' : 'title-details-origin' } )\n",
    "        atag = res.find('a')\n",
    "        atag = atag.text\n",
    "        CountryOriginN.append(atag)\n",
    "    except:\n",
    "        CountryOriginN.append(empty_val)  \n",
    "        \n",
    "    try:\n",
    "        res = soup.find('li',  { 'data-testid' : 'title-details-languages' } )\n",
    "        lang = res.find('a')\n",
    "        lang = lang.text \n",
    "        LanguageN.append(lang)\n",
    "    except:\n",
    "        LanguageN.append(empty_val)\n",
    "        \n",
    "    try:\n",
    "        res = soup.find('li',  { 'data-testid' : 'title-details-filminglocations' } )\n",
    "        loc = res.find('a', { 'class' : \"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\"} )\n",
    "        loc = loc.text \n",
    "        LocationN.append(loc) \n",
    "    except:\n",
    "        LocationN.append(empty_val)\n",
    "\n",
    "    try:\n",
    "        ress = soup.find('li',  { 'data-testid' : 'title-details-akas' } )\n",
    "        akaname = ress.find('span', { 'class' : \"ipc-metadata-list-item__list-content-item\"} )\n",
    "        akaname  = akaname.text \n",
    "        AnotherMovieNAMEN.append(akaname)\n",
    "    except:\n",
    "        AnotherMovieNAMEN.append(empty_val)\n",
    "            \n",
    "    try:\n",
    "        res = soup.find('li',  { 'data-testid' : 'title-details-companies' } )\n",
    "        resw = res.find_all('a', \n",
    "                    { 'class' : 'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link' } )\n",
    "        miniWordss.clear()\n",
    "        for a_t in resw: \n",
    "            miniWordss.append(a_t.text) \n",
    "        ProdCompanyN.append(miniWordss)\n",
    "    except:\n",
    "        ProdCompanyN.append(empty_val)\n",
    "        \n",
    "    try:\n",
    "\n",
    "        res = soup.find('li',  { 'data-testid' : 'title-boxoffice-budget' } )\n",
    "        budgetNEW = res.find('span', { 'class' : 'ipc-metadata-list-item__list-content-item' } )\n",
    "        budgetNEW = budgetNEW.text\n",
    "        budgetNEW=budgetNEW.replace('(estimated)', '')\n",
    "        BudgetN.append(budgetNEW)\n",
    "    except:\n",
    "        BudgetN.append(empty_val)\n",
    "        \n",
    "    try:\n",
    "        res = soup.find('li',  { 'data-testid' : 'title-techspec_soundmix' } )\n",
    "        resw = res.find_all('a', \n",
    "                    { 'class' : 'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link' } )\n",
    "        miniWordsss.clear()\n",
    "        for a_t in resw: \n",
    "            miniWordsss.append(a_t.text) \n",
    "        SoundmixN.append(miniWordsss)\n",
    "    except:\n",
    "        SoundmixN.append(empty_val)\n",
    "      \n",
    "        \n",
    "    try:\n",
    "        res = soup.find('li',  { 'data-testid' : 'title-techspec_aspectratio' } )\n",
    "        aspc = res.find_all('span', { 'class' : 'ipc-metadata-list-item__list-content-item' } )\n",
    "        miniw.clear()\n",
    "        for sp in aspc: \n",
    "            miniw.append(sp.text) \n",
    "        AspectRatioN.append(miniw)\n",
    "    except:\n",
    "        AspectRatioN.append(empty_val)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589dc42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#those are unknown for future movies \n",
    "for e in range(0,FM_Amount):\n",
    "    WorldwideIncomeF.append(empty_val) \n",
    "    InternationalIncomeF.append(empty_val)\n",
    "    DomesticIncomeF.append(empty_val) \n",
    "    DomesicIncomePercentF.append(empty_val)\n",
    "    InternationalIncomePercentF.append(empty_val)\n",
    "    DomisticOpeningValF.append(empty_val)\n",
    "    DomesticDistributorF.append(empty_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b8709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some finance editing\n",
    "for r in range(0,FM_Amount): \n",
    "    if( ((isinstance(BudgetN[r],int))!= 1) & (BudgetN[r] != None) ):\n",
    "        BN = BudgetN[r].replace(',', '') \n",
    "        BN = BN.replace('$','')   \n",
    "        BN = BN.replace('€','')  \n",
    "        BN = int(BN)\n",
    "        BudgetN[r] = BN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba88073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some finance editing\n",
    "\n",
    "for r in range(0,1000):  \n",
    "    if( ((isinstance(Budget[r],int))!= 1) & (Budget[r] != None) ):\n",
    "        B = Budget[r].replace(',', '') \n",
    "        B = B.replace('$','')   \n",
    "        B = int(B)\n",
    "        Budget[d] = B \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd447773",
   "metadata": {},
   "source": [
    "# Creating the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b75ded",
   "metadata": {},
   "source": [
    "In the following blocks we will consolidate the lists of past films and the lists of future films,  \n",
    "Each list will be united : Past + Future (Our first 1000 are past movies and 714 later are future movies)  \n",
    "Then we will build our DataFrame with our final lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list concatinations \n",
    "Rank =   rank + rankN\n",
    "MPAA_Rating = MPAA_Rating + MPAAN\n",
    "Link =   linkP + linkN\n",
    "Generes = Generes + GenerN\n",
    "Name =  title + titleN\n",
    "RunningTime =  RunningTime + RunTimeN\n",
    "DomesticDistributor = DomesticDistributor + DomesticDistributorF\n",
    "Budget = Budget + BudgetN\n",
    "WorldwideIncome = WorldwideIncome  + WorldwideIncomeF \n",
    "InternationalIncome = InternationalIncome  + InternationalIncomeF \n",
    "DomesticIncome = DomesticIncome+ DomesticIncomeF \n",
    "DomesicIncomePercent = DomesicIncomePercent + DomesicIncomePercentF \n",
    "InternationalIncomePercent = InternationalIncomePercent + InternationalIncomePercentF \n",
    "TextShortCut = TextShortCut + TextShortCutN\n",
    "DomisticOpeningVal = DomisticOpeningVal+ DomisticOpeningValF \n",
    "Date = Date + DateN\n",
    "Language = LanguageP + LanguageN\n",
    "Director = DirectorP + DirectorN\n",
    "Location = LocationP + LocationN\n",
    "MovieTrack = MovieTrackP + MovieTrackN\n",
    "Year = year + yearN\n",
    "Stars = StarsP + MainStarN\n",
    "CountryOrigin = CountryOriginP + CountryOriginN\n",
    "ProdCompany = ProdCompanyP + ProdCompanyN\n",
    "AnotherMovieNAME = AnotherMovieNAMEP + AnotherMovieNAMEN\n",
    "MovieStatus = MovieStatusP + MovieStatN\n",
    "SoundMix = SoundMixP + SoundmixN\n",
    "AspectRatio = AspectRatioP + AspectRatioN\n",
    "SecondStar = star2P + SecondStarN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a189503",
   "metadata": {},
   "source": [
    "# Building the Final DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1329dcc",
   "metadata": {},
   "source": [
    "This is almost the final part, each list is linked to its colum in our MOVIES DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a52b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the DATAFRAME dictionary \n",
    "DataFrame =  { \n",
    "'Rank':  Rank  , \n",
    "'MPAA Rating':   MPAA_Rating, \n",
    "'Name' : Name, \n",
    "' Link ': Link , \n",
    "' Generes' : Generes , \n",
    "'RunningTime': RunningTime  , \n",
    "'DomesticDistributor': DomesticDistributor , \n",
    "'Budget': Budget , \n",
    "'Worldwide Income': WorldwideIncome , \n",
    "'International Income': InternationalIncome  , \n",
    "'Domestic Income': DomesticIncome , \n",
    "'Domesic Income Percent' : DomesicIncomePercent , \n",
    "'International Income Percent': InternationalIncomePercent , \n",
    "'Text ShortCut' : TextShortCut , \n",
    "'Domistic Opening Value': DomisticOpeningVal , \n",
    "'Date': Date  , \n",
    "'Language': Language  , \n",
    "'Director': Director  , \n",
    "'Location': Location , \n",
    "'Movie Track': MovieTrack , \n",
    "'Year': Year  , \n",
    "'Stars': Stars  , \n",
    "'Country Origin': CountryOrigin , \n",
    "'Production Company': ProdCompany , \n",
    "'Another Movie NAME': AnotherMovieNAME , \n",
    "'Movie Status': MovieStatus , \n",
    "'Sound Mix': SoundMix  , \n",
    "'Aspect Ratio': AspectRatio  , \n",
    "'Second Star':  SecondStar    \n",
    "} \n",
    "# creating the DATAFRAME dictionary \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_project = pd.DataFrame(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_project.to_csv('C:/DS_PROJECT/file_name.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc8852",
   "metadata": {},
   "source": [
    "### This is the end of Part 1 of our Data Science Project,  \n",
    "\n",
    "### from now we will load our final CSV file, to next parts of our mission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f4463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
